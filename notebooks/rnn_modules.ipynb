{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some useful modules for RNNs in pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import writefile_run\n",
    "filename = '../package/pytorch_utils/wrapped_lstm.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run $filename\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Module which wraps an input and output module around an LSTM.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapped LSTM with input and output modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run $filename -a\n",
    "\n",
    "\n",
    "class WrappedLSTM(nn.Module):\n",
    "    def __init__(self, lstm_input_size, lstm_hidden_size, input_module=None, output_module=None, num_layers=1):\n",
    "        \"\"\"\n",
    "        lstm_input_size should equal input_module output size\n",
    "        lstm_hidden_size should equal output_module input size\n",
    "        \"\"\"\n",
    "        super(WrappedLSTM, self).__init__()\n",
    "        \n",
    "        self.input_module = input_module\n",
    "        self.output_module = output_module\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=lstm_input_size,hidden_size=lstm_hidden_size, num_layers=num_layers)\n",
    "        \n",
    "    def forward(self,hidden, *packed_input):\n",
    "        \"\"\"\n",
    "        Applies input module to data in packed_inputs, \n",
    "        then applies the LSTM layers,\n",
    "        Applied output module to output data of rnn,\n",
    "        \n",
    "        Returns packed output sequence and final hidden state of LSTM.\n",
    "        \"\"\"\n",
    "        batch_sizes = packed_input[0].batch_sizes\n",
    "        \n",
    "        if self.input_module != None:\n",
    "            rnn_input = self.input_module(*[p.data for p in packed_input])\n",
    "            rnn_input = utils.PackedSequence(rnn_input,batch_sizes)\n",
    "        else:\n",
    "            rnn_input = packed_input[0]\n",
    "            \n",
    "        rnn_output, hidden = self.lstm(rnn_input,hidden)\n",
    "        \n",
    "        if self.output_module != None:\n",
    "            output = self.output_module(rnn_output.data)\n",
    "            output = utils.PackedSequence(output,batch_sizes)\n",
    "        else:\n",
    "            output = rnn_output\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTMmodel(nn.Module):\n",
    "    def __init__(self,num_embeddings, embedding_size, lstm_hidden_size, num_layers=1):\n",
    "        \"\"\"\n",
    "        num_embeddings sized input and outputs.\n",
    "        lstm output interfaced to final output through Dense layer.\n",
    "        \"\"\"\n",
    "        super(MyLSTMmodel, self).__init__()\n",
    "        \n",
    "        embed = nn.Embedding(num_embeddings, embedding_size)\n",
    "        \n",
    "        # hidden to output\n",
    "        h2o = nn.Linear(lstm_hidden_size, num_embeddings)\n",
    "        \n",
    "        self.wrappedlstm = WrappedLSTM(embedding_size, lstm_hidden_size,embed, h2o,num_layers=num_layers)\n",
    "        \n",
    "        self.hidden_size = lstm_hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "    def forward(self, packed_input, hidden):\n",
    "        packed_output, hidden = self.wrappedlstm(packed_input, hidden)\n",
    "        return packed_output, hidden\n",
    "    \n",
    "    def initHidden(self, num_seqs):\n",
    "        return (torch.rand(self.num_layers,num_seqs,self.hidden_size),\n",
    "                torch.rand(self.num_layers,num_seqs,self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = MyLSTMmodel(10,100,100,num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.LongTensor([0,4,1,1,2])\n",
    "b = torch.LongTensor([3,7,6,5])\n",
    "c = torch.LongTensor([8,1])\n",
    "sample_input = utils.pack_sequence([a,b,c])\n",
    "sample_hidden = lstm.initHidden(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = lstm(sample_hidden,sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 0.0977,  0.0047,  0.1723, -0.0532,  0.2271,  0.2114, -0.0280,\n",
       "         -0.0200, -0.0315,  0.0284],\n",
       "        [ 0.1886,  0.0175,  0.1198, -0.0272,  0.2438,  0.2450,  0.0635,\n",
       "          0.0546,  0.0195,  0.0870],\n",
       "        [ 0.0810, -0.0442,  0.1582, -0.0489,  0.2122,  0.1573, -0.0846,\n",
       "         -0.0411, -0.0178,  0.0773],\n",
       "        [ 0.0916,  0.0159,  0.1076, -0.0891,  0.1828,  0.1796, -0.0201,\n",
       "          0.0178,  0.0028,  0.0753],\n",
       "        [ 0.1512, -0.0135,  0.1055, -0.0557,  0.1852,  0.1878, -0.0095,\n",
       "          0.0680,  0.0164,  0.1166],\n",
       "        [ 0.0697, -0.0740,  0.1117, -0.1219,  0.1426,  0.1006, -0.0587,\n",
       "         -0.0058, -0.0324,  0.1461],\n",
       "        [ 0.0925,  0.0025,  0.0698, -0.1073,  0.1409,  0.1123, -0.0376,\n",
       "          0.0218,  0.0152,  0.1058],\n",
       "        [ 0.1072, -0.0421,  0.0735, -0.0550,  0.1302,  0.1511, -0.0303,\n",
       "          0.0637,  0.0422,  0.1428],\n",
       "        [ 0.1013, -0.0092,  0.0460, -0.1180,  0.1158,  0.0621, -0.0503,\n",
       "          0.0202,  0.0229,  0.1225],\n",
       "        [ 0.0917, -0.0595,  0.0603, -0.0556,  0.1154,  0.1272, -0.0360,\n",
       "          0.0511,  0.0409,  0.1361],\n",
       "        [ 0.1039, -0.0383,  0.0452, -0.1203,  0.1068,  0.0452, -0.0509,\n",
       "          0.0187,  0.0256,  0.1486]]), batch_sizes=tensor([ 3,  3,  2,  2,  1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 100])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_py36]",
   "language": "python",
   "name": "conda-env-pytorch_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
