{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convenience module for pytorch training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import writefile_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run train_utils.py\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Concenvience module for pytorch training and visualization.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from pylab import *\n",
    "from torch.utils.data import *\n",
    "from IPython import display\n",
    "import os\n",
    "\n",
    "style.use(['dark_background'])\n",
    "rcParams['axes.grid']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup a model for MNIST to demo the module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mnist = MNIST('/MNIST',download=True,transform=ToTensor())\n",
    "test_mnist = MNIST('/MNIST',train=False,transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_mnist, batch_size=32,shuffle=True)\n",
    "test_loader = DataLoader(test_mnist, batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistClassifier(nn.Module):\n",
    "    def __init__(self, hid_size):\n",
    "        super(MnistClassifier, self).__init__()\n",
    "        \n",
    "        self.hidden_layer = nn.Linear(28*28,hid_size)\n",
    "        \n",
    "        self.output_layer = nn.Linear(hid_size,10)\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        input = input.view(-1,28*28)\n",
    "        \n",
    "        out = F.relu(self.hidden_layer(input))\n",
    "        out = self.output_layer(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistClassifier(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTimeName():\n",
    "    \"\"\"Return the current time in format <day>-<month>_<hour><minute> for use in filenames.\"\"\"\n",
    "    from datetime import datetime\n",
    "    t = datetime.now()\n",
    "    return \"{:02d}-{:02d}_{:02d}{:02d}\".format(t.day,t.month,t.hour,t.minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainOnBatch(model,batch,optimizer):\n",
    "    outputs = model(batch[0])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(outputs,batch[1])\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "save_every = 1\n",
    "save_dir = 'testinglol'\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor=0.2,cooldown=60,patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<progress style='width:60ex' max='1875' value='0'></progress>"
      ],
      "text/plain": [
       "[                                                            ] 0/1875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'testinglol\\\\LossPlot.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-9d07f16ebba8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mplotpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"LossPlot.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplotpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tight'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mlossplot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplotpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplay_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loss_plot'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\pytorch_py36\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    702\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\pytorch_py36\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(self, fname, **kwargs)\u001b[0m\n\u001b[0;32m   1832\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_frameon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1834\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1835\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1836\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\pytorch_py36\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[0;32m   2265\u001b[0m                 \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2266\u001b[0m                 \u001b[0mbbox_inches_restore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2267\u001b[1;33m                 **kwargs)\n\u001b[0m\u001b[0;32m   2268\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2269\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\pytorch_py36\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m             \u001b[0mfilename_or_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    513\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'testinglol\\\\LossPlot.png'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23cf96db080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = []\n",
    "loss=0\n",
    "batch_num=10\n",
    "gn = 0\n",
    "d = display.display('', display_id='loss_print')\n",
    "epoch_progress = display.ProgressBar(len(train_loader))\n",
    "bar = display.display(epoch_progress,display_id='progress_bar')\n",
    "fig, ax = subplots(1,1, figsize = (18,6))\n",
    "\n",
    "loss_line, = ax.plot([1],[0])\n",
    "\n",
    "plotpath = os.path.join(save_dir,\"LossPlot.png\")\n",
    "savefig(plotpath, bbox_inches='tight')\n",
    "\n",
    "lossplot = display.display(display.Image(plotpath),display_id='loss_plot')\n",
    "k=0\n",
    "for e in range(epochs):\n",
    "    i=0\n",
    "    grad_norm=0\n",
    "    for batch in train_loader:\n",
    "        loss = trainOnBatch(model,batch, optimizer)\n",
    "        loss = loss.detach().cpu().numpy()\n",
    "        grad_norm = max(grad_norm, gn)\n",
    "        i+=1\n",
    "        if i%batch_num==0:\n",
    "            k+=1\n",
    "            toprint = \"Epoch {}, batch {}, lr={:.6f}, loss={:.5f}\".format(e+1,i,\n",
    "                                optimizer.state_dict()['param_groups'][0]['lr'],loss)\n",
    "            disp_obj = display.Markdown(toprint)\n",
    "            d.update(disp_obj)\n",
    "            epoch_progress.progress = i\n",
    "            bar.update(epoch_progress)\n",
    "            #plot(losses)\n",
    "            #show()\n",
    "            losses.append(loss)\n",
    "        #     ax.set_xlim(0,e+2)\n",
    "        #     ax.set_ylim(0,max(losses)*1.2)\n",
    "\n",
    "            loss_line.set_xdata(arange(k)+1)\n",
    "            loss_line.set_ydata(losses)\n",
    "\n",
    "\n",
    "            ax.relim()\n",
    "            ax.autoscale()\n",
    "            xl,xr = ax.get_xlim()\n",
    "            ax.set_xlim((0,None))\n",
    "        #     ax.set_xlim(0,4.6)\n",
    "\n",
    "            yl,yr = ax.get_ylim()\n",
    "            ax.set_ylim(0,yr)\n",
    "\n",
    "            savefig(plotpath, bbox_inches='tight')\n",
    "\n",
    "            lossplot.update(display.Image(plotpath))\n",
    " \n",
    "   \n",
    "    scheduler.step(loss)\n",
    "   \n",
    "    \n",
    "    \n",
    "    if e%(save_every)==0:\n",
    "        print(\"Saving model at {}\".format(getTimeName()))\n",
    "        torch.save(model.state_dict(), \n",
    "                   os.path.join(save_dir,\"{}_epoch{:03d}_loss_{:.5f}\".format(getTimeName(),e+1,loss)))\n",
    "        \n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_py36]",
   "language": "python",
   "name": "conda-env-pytorch_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
