{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some useful modules for RNNs in pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import writefile_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run wrappedLSTM.py\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Module which wraps an input and output module around an LSTM.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapped LSTM with input and output modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run wrappedLSTM.py -a\n",
    "\n",
    "\n",
    "class WrappedLSTM(nn.Module):\n",
    "    def __init__(self, lstm_input_size, lstm_hidden_size, input_module=None, output_module=None, num_layers=1):\n",
    "        \"\"\"\n",
    "        lstm_input_size should equal input_module output size\n",
    "        lstm_hidden_size should equal output_module input size\n",
    "        \"\"\"\n",
    "        super(WrappedLSTM, self).__init__()\n",
    "        \n",
    "        self.input_module = input_module\n",
    "        self.output_module = output_module\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=lstm_input_size,hidden_size=lstm_hidden_size, num_layers=num_layers)\n",
    "        \n",
    "    def forward(self,hidden, *packed_input):\n",
    "        \"\"\"\n",
    "        Applies input module to data in packed_inputs, \n",
    "        then applies the LSTM layers,\n",
    "        Applied output module to output data of rnn,\n",
    "        \n",
    "        Returns packed output sequence and final hidden state of LSTM.\n",
    "        \"\"\"\n",
    "        batch_sizes = packed_input[0].batch_sizes\n",
    "        \n",
    "        if self.input_module != None:\n",
    "            rnn_input = self.input_module(*[p.data for p in packed_input])\n",
    "            rnn_input = utils.PackedSequence(rnn_input,batch_sizes)\n",
    "        else:\n",
    "            rnn_input = packed_input[0]\n",
    "            \n",
    "        rnn_output, hidden = self.lstm(rnn_input,hidden)\n",
    "        \n",
    "        if self.output_module != None:\n",
    "            output = self.output_module(rnn_output.data)\n",
    "            output = utils.PackedSequence(output,batch_sizes)\n",
    "        else:\n",
    "            output = rnn_output\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTMmodel(nn.Module):\n",
    "    def __init__(self,num_embeddings, embedding_size, lstm_hidden_size, num_layers=1):\n",
    "        \"\"\"\n",
    "        num_embeddings sized input and outputs.\n",
    "        lstm output interfaced to final output through Dense layer.\n",
    "        \"\"\"\n",
    "        super(MyLSTMmodel, self).__init__()\n",
    "        \n",
    "        embed = nn.Embedding(num_embeddings, embedding_size)\n",
    "        \n",
    "        # hidden to output\n",
    "        h2o = nn.Linear(lstm_hidden_size, num_embeddings)\n",
    "        \n",
    "        self.wrappedlstm = WrappedLSTM(embedding_size, lstm_hidden_size,embed, h2o,num_layers=num_layers)\n",
    "        \n",
    "        self.hidden_size = lstm_hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "    def forward(self, packed_input, hidden):\n",
    "        packed_output, hidden = self.wrappedlstm(packed_input, hidden)\n",
    "        return packed_output, hidden\n",
    "    \n",
    "    def initHidden(self, num_seqs):\n",
    "        return (torch.rand(self.num_layers,num_seqs,self.hidden_size),\n",
    "                torch.rand(self.num_layers,num_seqs,self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = MyLSTMmodel(10,100,100,num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.LongTensor([0,4,1,1,2])\n",
    "b = torch.LongTensor([3,7,6,5])\n",
    "c = torch.LongTensor([8,1])\n",
    "sample_input = utils.pack_sequence([a,b,c])\n",
    "sample_hidden = lstm.initHidden(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = lstm(sample_hidden,sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 4.5356e-02, -1.3117e-02, -7.5379e-02,  1.8073e-01,  2.2724e-03,\n",
       "         -2.0360e-01, -9.1893e-02, -9.3743e-02,  1.4752e-01, -1.1098e-01],\n",
       "        [ 1.9661e-02, -1.3342e-01, -9.6478e-03,  1.0177e-01,  1.2161e-02,\n",
       "         -2.2733e-01, -9.8890e-02, -4.4546e-02,  9.2363e-02,  8.4648e-02],\n",
       "        [ 5.2866e-02, -1.0012e-01, -6.6004e-02,  2.2615e-01,  6.1098e-02,\n",
       "         -1.9439e-01, -1.0957e-01, -7.8684e-02,  7.6870e-02, -1.3136e-01],\n",
       "        [ 1.4732e-02, -1.7848e-02, -9.9732e-03,  1.4387e-01,  3.3322e-02,\n",
       "         -1.6140e-01, -7.7387e-02, -4.4499e-02,  1.0875e-01, -9.5107e-02],\n",
       "        [-6.1885e-02, -6.9286e-02,  4.2829e-02,  9.8437e-02,  2.0012e-02,\n",
       "         -1.4493e-01, -9.0458e-02, -4.3558e-02,  7.0776e-02,  3.8683e-02],\n",
       "        [ 1.1775e-04, -8.9769e-02, -1.9824e-02,  1.5231e-01,  3.3981e-02,\n",
       "         -1.7862e-01, -8.4037e-02, -5.4298e-02,  6.8807e-02, -1.3086e-01],\n",
       "        [ 1.0023e-02, -2.5405e-02,  1.0689e-02,  1.0071e-01,  3.5320e-02,\n",
       "         -1.5308e-01, -5.5132e-02, -2.7476e-02,  1.0158e-01, -8.7615e-02],\n",
       "        [-8.6300e-02, -3.3442e-02,  5.5083e-02,  7.6547e-02,  1.6706e-03,\n",
       "         -1.1968e-01, -6.2052e-02, -3.3917e-02,  5.3566e-02, -2.4356e-02],\n",
       "        [ 1.6549e-02, -2.8795e-02,  1.3063e-02,  7.2836e-02,  2.8002e-02,\n",
       "         -1.5297e-01, -3.3523e-02, -2.8262e-02,  9.7217e-02, -9.0624e-02],\n",
       "        [-9.0185e-02, -6.3718e-03,  5.5550e-02,  6.2836e-02,  3.9994e-03,\n",
       "         -1.0418e-01, -4.0596e-02, -3.0763e-02,  3.7524e-02, -6.8209e-02],\n",
       "        [ 3.5847e-06, -3.0679e-02,  2.6405e-02,  7.7165e-02,  2.2847e-02,\n",
       "         -1.2569e-01, -3.2470e-02, -9.1594e-03,  1.0687e-01, -6.8643e-02]]), batch_sizes=tensor([ 3,  3,  2,  2,  1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 100])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_py36]",
   "language": "python",
   "name": "conda-env-pytorch_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
