{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some useful modules for RNNs in pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import writefile_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run wrappedLSTM.py\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Module which wraps an input and output module around an LSTM.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapped LSTM with input and output modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile_run wrappedLSTM.py -a\n",
    "\n",
    "\n",
    "class WrappedLSTM(nn.Module):\n",
    "    def __init__(self, lstm_input_size, lstm_hidden_size, input_module=None, output_module=None):\n",
    "        \"\"\"\n",
    "        lstm_input_size should equal input_module output size\n",
    "        lstm_hidden_size should equal output_module input size\n",
    "        \"\"\"\n",
    "        super(WrappedLSTM, self).__init__()\n",
    "        \n",
    "        self.input_module = input_module\n",
    "        self.output_module = output_module\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=lstm_input_size,hidden_size=lstm_hidden_size)\n",
    "        \n",
    "    def forward(self,hidden, *packed_input):\n",
    "        \"\"\"\n",
    "        Applies input module to data in packed_inputs, \n",
    "        then applies the LSTM layers,\n",
    "        Applied output module to output data of rnn,\n",
    "        \n",
    "        Returns packed output sequence and final hidden state of LSTM.\n",
    "        \"\"\"\n",
    "        batch_sizes = packed_input[0].batch_sizes\n",
    "        \n",
    "        if self.input_module != None:\n",
    "            rnn_input = self.input_module(*[p.data for p in packed_input])\n",
    "            rnn_input = utils.PackedSequence(rnn_input,batch_sizes)\n",
    "        else:\n",
    "            rnn_input = packed_input[0]\n",
    "            \n",
    "        rnn_output, hidden = self.lstm(rnn_input,hidden)\n",
    "        \n",
    "        if self.output_module != None:\n",
    "            output = self.output_module(rnn_output.data)\n",
    "            output = utils.PackedSequence(output,batch_sizes)\n",
    "        else:\n",
    "            output = rnn_output\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTMmodel(nn.Module):\n",
    "    def __init__(self,num_embeddings, embedding_size, lstm_hidden_size):\n",
    "        \"\"\"\n",
    "        num_embeddings sized input and outputs.\n",
    "        lstm output interfaced to final output through Dense layer.\n",
    "        \"\"\"\n",
    "        super(MyLSTMmodel, self).__init__()\n",
    "        \n",
    "        embed = nn.Embedding(num_embeddings, embedding_size)\n",
    "        \n",
    "        # hidden to output\n",
    "        h2o = nn.Linear(lstm_hidden_size, num_embeddings)\n",
    "        \n",
    "        self.wrappedlstm = WrappedLSTM(embedding_size, lstm_hidden_size,embed, h2o)\n",
    "        \n",
    "        self.hidden_size = lstm_hidden_size\n",
    "        \n",
    "    def forward(self, packed_input, hidden):\n",
    "        packed_output, hidden = self.wrappedlstm(packed_input, hidden)\n",
    "        return packed_output, hidden\n",
    "    \n",
    "    def initHidden(self, num_seqs):\n",
    "        return torch.rand(1,num_seqs,self.hidden_size),torch.rand(1,num_seqs,self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = MyLSTMmodel(10,100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.LongTensor([0,4,1,1,2])\n",
    "b = torch.LongTensor([3,7,6,5])\n",
    "c = torch.LongTensor([8,1])\n",
    "sample_input = utils.pack_sequence([a,b,c])\n",
    "sample_hidden = lstm.initHidden(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = lstm(sample_hidden,sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-0.0884, -0.1806,  0.0011,  0.0866, -0.2564,  0.0708,  0.0576,\n",
       "         -0.0129, -0.1135,  0.2793],\n",
       "        [-0.0395, -0.1614,  0.1557,  0.0780, -0.2334, -0.0519,  0.2044,\n",
       "         -0.1434, -0.1146,  0.1510],\n",
       "        [-0.1149, -0.1372,  0.0092,  0.1239, -0.0211, -0.0837,  0.0748,\n",
       "          0.1177, -0.1419,  0.1817],\n",
       "        [ 0.0140, -0.2058,  0.0085,  0.0069, -0.1778, -0.1465,  0.1653,\n",
       "         -0.1534, -0.0208,  0.0347],\n",
       "        [-0.0557, -0.2501,  0.0651, -0.0138, -0.2018, -0.1098,  0.1882,\n",
       "         -0.0545, -0.0771, -0.0480],\n",
       "        [-0.1886, -0.0810,  0.0456,  0.2567,  0.0308, -0.0172,  0.1563,\n",
       "          0.1002,  0.0006,  0.0404],\n",
       "        [-0.1456, -0.0798,  0.0083,  0.1486, -0.0440, -0.0441,  0.1614,\n",
       "         -0.0626,  0.1085, -0.0141],\n",
       "        [-0.0750, -0.0297,  0.1732,  0.0842, -0.0558, -0.1382,  0.1308,\n",
       "         -0.0385, -0.1046,  0.0234],\n",
       "        [-0.1973, -0.0132,  0.0204,  0.2051, -0.0107,  0.0015,  0.1529,\n",
       "          0.0130,  0.1564, -0.0597],\n",
       "        [-0.1730, -0.0450,  0.1867,  0.0543, -0.0890, -0.1422,  0.1281,\n",
       "          0.0607,  0.0591,  0.0671],\n",
       "        [ 0.0080, -0.0231,  0.0903,  0.1005, -0.0584, -0.2170,  0.1760,\n",
       "         -0.0893,  0.1554, -0.0199]]), batch_sizes=tensor([ 3,  3,  2,  2,  1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_py36]",
   "language": "python",
   "name": "conda-env-pytorch_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
